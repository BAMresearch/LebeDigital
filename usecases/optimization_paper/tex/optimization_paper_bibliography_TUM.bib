
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% -- Ref for TUM DDMM -------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@misc{schulman_gradient_2016,
	title = {Gradient {Estimation} {Using} {Stochastic} {Computation} {Graphs}},
	url = {http://arxiv.org/abs/1506.05254},
	abstract = {In a variety of problems originating in supervised, unsupervised, and reinforcement learning, the loss function is defined by an expectation over a collection of random variables, which might be part of a probabilistic model or the external world. Estimating the gradient of this loss function, using samples, lies at the core of gradient-based learning algorithms for these problems. We introduce the formalism of stochastic computation graphs---directed acyclic graphs that include both deterministic functions and conditional probability distributions---and describe how to easily and automatically derive an unbiased estimator of the loss function's gradient. The resulting algorithm for computing the gradient estimator is a simple modification of the standard backpropagation algorithm. The generic scheme we propose unifies estimators derived in variety of prior work, along with variance-reduction techniques therein. It could assist researchers in developing intricate models involving a combination of stochastic and deterministic operations, enabling, for example, attention, memory, and control actions.},
	urldate = {2022-10-18},
	publisher = {arXiv},
	author = {Schulman, John and Heess, Nicolas and Weber, Theophane and Abbeel, Pieter},
	month = jan,
	year = {2016},
	note = {arXiv:1506.05254 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Advances in Neural Information Processing Systems 28 (NIPS 2015)},
	file = {arXiv Fulltext PDF:/home/atul_0711/Zotero/storage/CCVNCRKR/Schulman et al. - 2016 - Gradient Estimation Using Stochastic Computation G.pdf:application/pdf;arXiv.org Snapshot:/home/atul_0711/Zotero/storage/RSMHV5GK/1506.html:text/html},
}

@inproceedings{wang_stochastic_2003,
	address = {Maui, HI, USA},
	title = {Stochastic optimization with inequality constraints using simultaneous perturbations and penalty functions},
	isbn = {978-0-7803-7924-4},
	url = {http://ieeexplore.ieee.org/document/1271742/},
	doi = {10.1109/CDC.2003.1271742},
	language = {en},
	urldate = {2022-10-28},
	booktitle = {42nd {IEEE} {International} {Conference} on {Decision} and {Control} ({IEEE} {Cat}. {No}.{03CH37475})},
	publisher = {IEEE},
	author = {Wang, I.-J. and Spall, J.C.},
	year = {2003},
	keywords = {Optimisation},
	pages = {3808--3813},
	file = {Wang and Spall - 2003 - Stochastic optimization with inequality constraint.pdf:/home/atul_0711/Zotero/storage/Y5QG7WYG/Wang and Spall - 2003 - Stochastic optimization with inequality constraint.pdf:application/pdf},
}


@article{cranmer2020frontier,
  title={The frontier of simulation-based inference},
  author={Cranmer, Kyle and Brehmer, Johann and Louppe, Gilles},
  journal={Proceedings of the National Academy of Sciences},
  volume={117},
  number={48},
  pages={30055--30062},
  year={2020},
  publisher={National Acad Sciences}
}
}

@inproceedings{wang_stochastic_2003,
	address = {Maui, HI, USA},
	title = {Stochastic optimization with inequality constraints using simultaneous perturbations and penalty functions},
	isbn = {978-0-7803-7924-4},
	url = {http://ieeexplore.ieee.org/document/1271742/},
	doi = {10.1109/CDC.2003.1271742},
	language = {en},
	urldate = {2022-10-28},
	booktitle = {42nd {IEEE} {International} {Conference} on {Decision} and {Control} ({IEEE} {Cat}. {No}.{03CH37475})},
	publisher = {IEEE},
	author = {Wang, I.-J. and Spall, J.C.},
	year = {2003},
	keywords = {Optimization},
	pages = {3808--3813},
	file = {Wang and Spall - 2003 - Stochastic optimization with inequality constraint.pdf:/home/atul_0711/Zotero/storage/Y5QG7WYG/Wang and Spall - 2003 - Stochastic optimization with inequality constraint.pdf:application/pdf},
}

@misc{bird_stochastic_2018,
	title = {Stochastic {Variational} {Optimization}},
	url = {http://arxiv.org/abs/1809.04855},
	abstract = {Variational Optimization forms a differentiable upper bound on an objective. We show that approaches such as Natural Evolution Strategies and Gaussian Perturbation, are special cases of Variational Optimization in which the expectations are approximated by Gaussian sampling. These approaches are of particular interest because they are parallelizable. We calculate the approximate bias and variance of the corresponding gradient estimators and demonstrate that using antithetic sampling or a baseline is crucial to mitigate their problems. We contrast these methods with an alternative parallelizable method, namely Directional Derivatives. We conclude that, for differentiable objectives, using Directional Derivatives is preferable to using Variational Optimization to perform parallel Stochastic Gradient Descent.},
	urldate = {2022-11-08},
	publisher = {arXiv},
	author = {Bird, Thomas and Kunze, Julius and Barber, David},
	month = sep,
	year = {2018},
	note = {arXiv:1809.04855 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Optimization},
	file = {arXiv Fulltext PDF:/home/atul_0711/Zotero/storage/CJXSJX5B/Bird et al. - 2018 - Stochastic Variational Optimization.pdf:application/pdf;arXiv.org Snapshot:/home/atul_0711/Zotero/storage/GQUCHMT2/1809.html:text/html},
}

@misc{staines_variational_2012,
	title = {Variational {Optimization}},
	url = {http://arxiv.org/abs/1212.4507},
	abstract = {We discuss a general technique that can be used to form a differentiable bound on the optima of non-differentiable or discrete objective functions. We form a unified description of these methods and consider under which circumstances the bound is concave. In particular we consider two concrete applications of the method, namely sparse learning and support vector classification.},
	urldate = {2022-11-08},
	publisher = {arXiv},
	author = {Staines, Joe and Barber, David},
	month = dec,
	year = {2012},
	note = {arXiv:1212.4507 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis, Statistics - Machine Learning, 65K10, G.1.6, Optimization},
	file = {arXiv Fulltext PDF:/home/atul_0711/Zotero/storage/CZYZ7LL9/Staines and Barber - 2012 - Variational Optimization.pdf:application/pdf;arXiv.org Snapshot:/home/atul_0711/Zotero/storage/SKWV6UJ6/1212.html:text/html},
}

@misc{dimitriev_arms_2021,
	title = {{ARMS}: {Antithetic}-{REINFORCE}-{Multi}-{Sample} {Gradient} for {Binary} {Variables}},
	shorttitle = {{ARMS}},
	url = {http://arxiv.org/abs/2105.14141},
	abstract = {Estimating the gradients for binary variables is a task that arises frequently in various domains, such as training discrete latent variable models. What has been commonly used is a REINFORCE based Monte Carlo estimation method that uses either independent samples or pairs of negatively correlated samples. To better utilize more than two samples, we propose ARMS, an Antithetic REINFORCE-based Multi-Sample gradient estimator. ARMS uses a copula to generate any number of mutually antithetic samples. It is unbiased, has low variance, and generalizes both DisARM, which we show to be ARMS with two samples, and the leave-one-out REINFORCE (LOORF) estimator, which is ARMS with uncorrelated samples. We evaluate ARMS on several datasets for training generative models, and our experimental results show that it outperforms competing methods. We also develop a version of ARMS for optimizing the multi-sample variational bound, and show that it outperforms both VIMCO and DisARM. The code is publicly available.},
	urldate = {2022-11-11},
	publisher = {arXiv},
	author = {Dimitriev, Alek and Zhou, Mingyuan},
	month = may,
	year = {2021},
	note = {arXiv:2105.14141 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Optimization},
	file = {arXiv Fulltext PDF:/home/atul_0711/Zotero/storage/AA2233GG/Dimitriev and Zhou - 2021 - ARMS Antithetic-REINFORCE-Multi-Sample Gradient f.pdf:application/pdf;arXiv.org Snapshot:/home/atul_0711/Zotero/storage/EVGZEJW4/2105.html:text/html},
}

@article{kool_buy_2022,
	title = {Buy 4 {REINFORCE} {Samples}, {Get} a {Baseline} for {Free}!},
	url = {https://openreview.net/forum?id=r1lgTGL5DE},
	abstract = {REINFORCE can be used to train models in structured prediction settings to directly optimize the test-time objective. However, the common case of sampling one prediction per datapoint (input) is data-inefficient. We show that by drawing multiple samples (predictions) per datapoint, we can learn with significantly less data, as we freely obtain a REINFORCE baseline to reduce variance. Additionally we derive a REINFORCE estimator with baseline, based on sampling without replacement. Combined with a recent technique to sample sequences without replacement using Stochastic Beam Search, this improves the training procedure for a sequence model that predicts the solution to the Travelling Salesman Problem.},
	language = {en},
	urldate = {2022-11-11},
	author = {Kool, Wouter and Hoof, Herke van and Welling, Max},
	month = jul,
	year = {2022},
	keywords = {Optimization},
	file = {Full Text PDF:/home/atul_0711/Zotero/storage/XU56YCJU/Kool et al. - 2022 - Buy 4 REINFORCE Samples, Get a Baseline for Free!.pdf:application/pdf;Snapshot:/home/atul_0711/Zotero/storage/IPJZPBQP/forum.html:text/html},
}

@article{byrne_sequential_2008,
	title = {Sequential unconstrained minimization algorithms for constrained optimization},
	volume = {24},
	issn = {0266-5611},
	url = {https://dx.doi.org/10.1088/0266-5611/24/1/015013},
	doi = {10.1088/0266-5611/24/1/015013},
	abstract = {The problem of minimizing a function f(x):RJ → R, subject to constraints on the vector variable x, occurs frequently in inverse problems. Even without constraints, finding a minimizer of f(x) may require iterative methods. We consider here a general class of iterative algorithms that find a solution to the constrained minimization problem as the limit of a sequence of vectors, each solving an unconstrained minimization problem. Our sequential unconstrained minimization algorithm (SUMMA) is an iterative procedure for constrained minimization. At the kth step we minimize the function to obtain xk. The auxiliary functions gk(x):D ⊆ RJ → R+ are nonnegative on the set D, each xk is assumed to lie within D, and the objective is to minimize the continuous function f:RJ → R over x in the set , the closure of D. We assume that such minimizers exist, and denote one such by . We assume that the functions gk(x) satisfy the inequalities for k = 2, 3, …. Using this assumption, we show that the sequence f(xk) is decreasing and converges to . If the restriction of f(x) to D has bounded level sets, which happens if is unique and f(x) is closed, proper and convex, then the sequence xk is bounded, and , for any cluster point x*. Therefore, if is unique, and . When is not unique, convergence can still be obtained, in particular cases. The SUMMA includes, as particular cases, the well-known barrier- and penalty-function methods, the simultaneous multiplicative algebraic reconstruction technique (SMART), the proximal minimization algorithm of Censor and Zenios, the entropic proximal methods of Teboulle, as well as certain cases of gradient descent and the Newton–Raphson method. The proof techniques used for SUMMA can be extended to obtain related results for the induced proximal distance method of Auslander and Teboulle.},
	language = {en},
	number = {1},
	urldate = {2022-11-14},
	journal = {Inverse Problems},
	author = {Byrne, Charles},
	month = jan,
	year = {2008},
	keywords = {Optimization},
	pages = {015013},
	file = {IOP Full Text PDF:/home/atul_0711/Zotero/storage/T3NQ7KN8/Byrne - 2008 - Sequential unconstrained minimization algorithms f.pdf:application/pdf},
}

@inproceedings{louppe_adversarial_2019,
	title = {Adversarial {Variational} {Optimization} of {Non}-{Differentiable} {Simulators}},
	url = {https://proceedings.mlr.press/v89/louppe19a.html},
	abstract = {Complex computer simulators are increasingly used across fields of science as generative models tying parameters of an underlying theory to experimental observations. Inference in this setup is often difficult, as simulators rarely admit a tractable density or likelihood function. We introduce Adversarial Variational Optimization (AVO), a likelihood-free inference algorithm for fitting a non-differentiable generative model incorporating ideas from generative adversarial networks, variational optimization and empirical Bayes. We adapt the training procedure of generative adversarial networks by replacing the differentiable generative network with a domain-specific simulator. We solve the resulting non-differentiable minimax problem by minimizing variational upper bounds of the two adversarial objectives. Effectively, the procedure results in learning a proposal distribution over simulator parameters, such that the JS divergence between the marginal distribution of the synthetic data and the empirical distribution of observed data is minimized. We evaluate and compare the method with simulators producing both discrete and continuous data.},
	language = {en},
	urldate = {2022-11-22},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Louppe, Gilles and Hermans, Joeri and Cranmer, Kyle},
	month = apr,
	year = {2019},
	note = {ISSN: 2640-3498},
	keywords = {Optimization},
	pages = {1438--1447},
	file = {Full Text PDF:/home/atul_0711/Zotero/storage/LGK9QAM5/Louppe et al. - 2019 - Adversarial Variational Optimization of Non-Differ.pdf:application/pdf;Supplementary PDF:/home/atul_0711/Zotero/storage/8WTL4KH8/Louppe et al. - 2019 - Adversarial Variational Optimization of Non-Differ.pdf:application/pdf},
}

@article{beaumont2002approximate,
  title={Approximate Bayesian computation in population genetics},
  author={Beaumont, Mark A and Zhang, Wenyang and Balding, David J},
  journal={Genetics},
  volume={162},
  number={4},
  pages={2025--2035},
  year={2002},
  publisher={Oxford University Press}
}

@article{marjoram2003markov,
  title={Markov chain Monte Carlo without likelihoods},
  author={Marjoram, Paul and Molitor, John and Plagnol, Vincent and Tavar{\'e}, Simon},
  journal={Proceedings of the National Academy of Sciences},
  volume={100},
  number={26},
  pages={15324--15328},
  year={2003},
  publisher={National Acad Sciences}
}

@inproceedings{staines2013optimization,
  title={Optimization by Variational Bounding.},
  author={Staines, Joe and Barber, David},
  booktitle={ESANN},
  year={2013}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@article{glynn1990likelihood,
  title={Likelihood ratio gradient estimation for stochastic systems},
  author={Glynn, Peter W},
  journal={Communications of the ACM},
  volume={33},
  number={10},
  pages={75--84},
  year={1990},
  publisher={ACM New York, NY, USA}
  }
  
@book{fiacco1990nonlinear,
  title={Nonlinear programming: sequential unconstrained minimization techniques},
  author={Fiacco, Anthony V and McCormick, Garth P},
  year={1990},
  publisher={SIAM}
}
@book{fortin2000augmented,
  title={Augmented Lagrangian methods: applications to the numerical solution of boundary-value problems},
  author={Fortin, Michel and Glowinski, Roland},
  year={2000},
  publisher={Elsevier}
}
@article{more2009benchmarking,
  title={Benchmarking derivative-free optimization algorithms},
  author={Mor{\'e}, Jorge J and Wild, Stefan M},
  journal={SIAM Journal on Optimization},
  volume={20},
  number={1},
  pages={172--191},
  year={2009},
  publisher={SIAM}
}

@article{larson2019derivative,
  title={Derivative-free optimization methods},
  author={Larson, Jeffrey and Menickelly, Matt and Wild, Stefan M},
  journal={Acta Numerica},
  volume={28},
  pages={287--404},
  year={2019},
  publisher={Cambridge University Press}
}

@article{neal1998view,
  title={A view of the EM algorithm that justifies incremental, sparse, and other variants},
  author={Neal, Radford M and Hinton, Geoffrey E},
  journal={Learning in graphical models},
  pages={355--368},
  year={1998},
  publisher={Springer}
}
